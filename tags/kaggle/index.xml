<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kaggle on そこのけそこのけゆとりが通る</title>
    <link>https://blog.regonn.tokyo/tags/kaggle/</link>
    <description>Recent content in kaggle on そこのけそこのけゆとりが通る</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 16 Oct 2019 09:00:00 +0900</lastBuildDate>
    
	<atom:link href="https://blog.regonn.tokyo/tags/kaggle/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kaggleコンペにチームで挑戦する時に工夫したこと</title>
      <link>https://blog.regonn.tokyo/data-science/2019-10-16-kaggle-team/</link>
      <pubDate>Wed, 16 Oct 2019 09:00:00 +0900</pubDate>
      
      <guid>https://blog.regonn.tokyo/data-science/2019-10-16-kaggle-team/</guid>
      <description>Kaggle のコンペって、周りに一緒にやってくれる人がいないと孤独な戦いになりやすいですよね。 かといって、チームにマージされるほどの実力も無いので、コンペの最初からメンバーを募集してチームを組み 、Kaggle の IEEE Fraud Detection コンペ に挑戦してみました。チームメンバーを募集するところから、やっていく中での気付き等をまとめておこうと思います。
私の紹介  れごん @regonn_haizine 島根県松江市に住んでる Web フリーランス データサイエンスの Podcast やってます regonn&amp;amp;curry.fm 挑戦したときは Kaggle コンペの参加経験はあるもののメダルは 0 枚  仲間集め 仲間集めは、最近 データラーニングギルド というコミュニティに所属したのもあって、そこの Slack で募集しました。
Kaggler の日本人コミュニティの Kaggler-ja とかでも、募集してみると色んな人が集まるかもしれませんね。
募集したあとに、やってるデータサイエンス Podcast の Discord チャンネル作ったので、こちらでも、今後は募集するかもしれません。かぐるーど
仲間集めで注意したこと IEEE コンペのチームは最大 5 人なので、もし応募が多すぎたら、抽選とかでも嫌なので、募集は複数チームも想定して Google Form で次のような項目を追加しておきました。(結果的には丁度 5 人だったので1チームでした)
 レベル感  チーム分けをしやすくするため、レベル感を聞いておく 1. 機械学習始めたて(半年位) 2. Python, R のどちらかを読んだり書いたりできる 3. 業務や研究で統計知識がある 4. Kaggle コンペメダルを持ってます  希望者が多い場合にはチームのリーダーをやってもいいか?  分ける場合にリーダーをやってもいいか聞いておく、データサイエンスの能力よりも、学生などでコンペ期間中に参加しやすさで決めてもらった   また、参加表明フォームには次のような注意書きもしておきました。</description>
    </item>
    
    <item>
      <title>重めのデータを扱う時のGPUを有効にしたGCP(GCE)の設定</title>
      <link>https://blog.regonn.tokyo/data-science/2019-10-13-gcp-for-data-science-competition/</link>
      <pubDate>Sun, 13 Oct 2019 09:00:00 +0900</pubDate>
      
      <guid>https://blog.regonn.tokyo/data-science/2019-10-13-gcp-for-data-science-competition/</guid>
      <description>最近の Kaggle 等のデータサイエンスコンペティションでは、データ量が大きく、クラウドで JupyterNotebook 用のインスタンスを立ち上げる際にも、メモリの関係等から GCP の設定をいじる必要があったので構築の際に気をつけていることをメモしておく。
目標 GPU が有効になった LightGBM を JupyterNotebook 上で動かせるようにする。 Docker は利用しない。
メモリを最大限に使えるようにする ※機械学習等の大きめのメモリを確保したい時の設定なので、一般サーバーでは非推奨
sudo sh -c &amp;quot;echo &#39;vm.overcommit_memory=1&#39; &amp;gt;&amp;gt; /etc/sysctl.conf &amp;amp;&amp;amp; sysctl -p&amp;quot;  GCP には Swap が無いので、Swap を追加する sudo dd if=/dev/zero of=/swapfile bs=1M count=10000 sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile  先に古い nvidia cuda 系を削除 sudo apt remove nvidia-* sudo apt remove cuda-*  GPU ドライバーインストール GPU の追加または削除 | Compute Engine ドキュメント | Google Cloud の記事の 「GPU ドライバのインストール」を参考に最新版を入れる</description>
    </item>
    
    <item>
      <title>Kaggleで容量の大きいcsvファイルを取り扱うには？(Postgresql編)</title>
      <link>https://blog.regonn.tokyo/data-science/2017-12-20-kaggle-postgresql/</link>
      <pubDate>Wed, 20 Dec 2017 09:41:28 +0900</pubDate>
      
      <guid>https://blog.regonn.tokyo/data-science/2017-12-20-kaggle-postgresql/</guid>
      <description>Kaggleをやってると大きめのCSVファイルデータが用意されていて処理に困ったので、今回はそれを Postgresql で処理して容量を減らして再びCSVにしていきます。
想定ファイル 今回は次のようなcsvを扱います。
sample.csv uuid,name,price,date xxxxxxxxxxxx,tomato,10,2017-10-19 yyyyyyyyyyyy,banana,8,2017-10-19  Postgres に DB を作ってアクセスする  入力ファイルがあるディレクトリで作業を行う sampleという名前のDBを作成する 登録されているユーザー名(username)でsample DBにアクセスする
$ ls # 入力ファイルがあるディレクトリで作業を行う sample.csv $ createdb sample $ psql -d sample -U (username)   Table を作る  samplesという Table を作成する。csvと同じ構成になるようにカラムを設定する \dで作ったTableが存在するかを確認
sample=# CREATE TABLE samples ( uuid varchar(80), name varchar(80), price int, date date ); sample=# \d List of relations Schema | Name | Type | Owner --------+---------+-------+-------- public | samples | table | username   ローカルのcsvをインポートする  今回は \copy でメタコマンドを使っているが、COPYコマンドを使う場合は絶対パスを指定してあげる header を追加することでcsvの最初の行を無視してくれる</description>
    </item>
    
    <item>
      <title>データサイエンティストを目指すための Kaggle チュートリアル</title>
      <link>https://blog.regonn.tokyo/data-science/2017-12-01-kaggle-tutorial/</link>
      <pubDate>Fri, 01 Dec 2017 09:41:28 +0900</pubDate>
      
      <guid>https://blog.regonn.tokyo/data-science/2017-12-01-kaggle-tutorial/</guid>
      <description>皆さんデータサイエンスしてますか？
機械学習の本読んだけど、MNISTやIrisデータの解析も飽きてきた(ディスっているわけではない)のであれば、実際の企業や団体が公開しているデータに触れることができるデータサイエンスコンペティションサイトのKaggleに挑戦してみましょう。
今回は、日本語対応しておらず少しハードルの高いKaggleのコンペティションに参加できるように、よく出てくる単語とかを説明していきます。
重要なKaggle用語 Kernels Kaggleで公開されているデータに対して、統計処理を行った結果や予測結果が公開されている。一流のプロが解析しているKernel等も見ることができ、評価の高いKernelのコードを写経するだけでも価値があると思う。
Competitions 企業が賞金を出したりして、参加者がより良い予測ができるモデルを作って競い合います。上部メニューのCompetitionsで飛ぶと一覧で出てきます。Activeというのが現在開催中のもので、最近(2017年12月)だと、メルカリが値段予測問題でコンペティションを開催しています。
Datasets 企業等が公開しているデータ。コンペティションではないので他のユーザーとは競わないですが、他のデータサイエンティストが公開しているKernelも見ることができるので、色々と参考になる。
Kaggleをどう利用したらいいのか？ 登録してみたものの、何をすればいいのか迷いますよね。これについては、KaggleのCTOが Quora という Q&amp;amp;Aサイト(実名版のヤフー知恵袋のようなもの)で回答した内容だと機械学習やAIを学ぶには次のようにKaggleを使っていくと良いそうです。(あまり英語得意じゃないので勝手な解釈になってるかもしれませんが間違ってたらコメントで指摘してください)
1. 興味のある問題を選ぶ 好きなものこそ上手なれという言葉もあるように、まず自分の興味ある分野のDatasetsを探してみましょう。画像を解析する問題や、株価を予測する問題が色々あります。Kaggleだとチュートリアル的な問題として、タイタニックの生存者予測や家の値段予想があります。
2. 一回愚直に問題を解いてみる あれこれ、アルゴリズムを考えたりしてドツボにはまるのであれば、一度愚直に、簡単な方法で解いてみましょう。例えば性別の情報が入っているなら、性別だけで一回予測してみて答えを出してみたりすると、精度は悪いですが回答できるようになります。
3. 最初のモデルを改善していく 一度回答は出せたので、今度はその回答の精度を上げてみます。先程の例ですと、性別の他に年齢を加えてみたり、使ったアルゴリズムの変数を調整して、どうすれば良い結果が得られるか色々試してみます。
4. 自分の解法を公開する ある程度、良い結果がでたら、Kernelを公開してみましょう。フィードバックを得られて学びになったり、高評価を得てKaggleのプロフィールの見栄えがよくなるかもしれません(就職・転職の際に使えそうですね)。日本語でフィードバックが欲しいならQiitaなどで公開しても良さそうですね。
5. 1~4を繰り返す 他の問題でも同じように解いてKernelを公開したり、他人のKernelを読んで勉強して色々な問題に対応できるようにしていきましょう。
6. Competitionに参加してみる 実力を付けたらCompetitionに挑戦してみましょう。(別に参加は無料なのでいきなりCompetitionに参加しても大丈夫です)
チーム機能もあったりするので、一緒にデータサイエンスを学んでいる人と協力して挑戦するのも良さそうです。
7. プロを目指して機械学習を実践していく ある程度、Competitionに慣れてきたら、実際に自分の仕事で機械学習を実践してみたり、転職などで使える環境に挑戦してみましょう。ここまでくると最新の論文を読んだり、良いコードの書き方を意識しだしたりするようです。(ちなみに私はまだこのレベルまで達してないです。)
あとは、自分が将来進む道(アカデミックな分野かAIエンジニアかデータサイエンティストなのか)も決めて専門性を高めていく必要があるみたいです。(なんか、ゲームの2次職みたいですね)
8. 他の人に教えてみる ここまできたら、実際に他の人にも教えてみましょう。
勉強会で発表したり、ブログや本を書いたり、アウトプットする方法は色々あると思います。他人に説明することで、自分のなかであやふやな部分とかも気づけたりするので大事ですね。
Kaggleで目指すもの KaggleではCompetitionで上位に入賞したり、高評価のKernelを作ったりすると、メダルがもらえて、そのメダルの種類と枚数によってランクが上がって行きます。最終的にはグランドマスターという称号が用意されているので、それを目指してみるのもいいですね。
宣伝 普段は田中TOMという名前でKaggleのコンペに挑戦するYoutube動画あげています。一緒にKaggleでプロフェッショナルの証であるMasterランクを手に入れましょう。
めざせKaggleMaster - YouTube</description>
    </item>
    
  </channel>
</rss>