---
layout: post
title: "2017年に触った(学んだ)機械学習の技術をまとめておく"
date: 2017-11-12 00:00:00
categories: 'programmer'
desc: "2017年に触ってきた、機械学習に関する技術をまとめていく"
keywords: "機械学習,ディープラーニング,マシンラーニング"
image: "https://blog.regonn.tokyo/images/2017-11-12-machine-learning.jpg"
---
<amp-img src="/images/2017-11-12-machine-learning.jpg" alt="パソコン" width="337px" height="250px" layout="responsive" ></amp-img>

2017年に入ってから機械学習系の技術を触り始めてYouTubeで学んだ内容を動画にして公開していった。
触り始めてから約1年経ったので、これまでの内容をまとめていく。
今はデータサイエンスの技術を競い合う[Kaggle](https://www.kaggle.com/)というサービスでMasterの称号を得るために相棒のJulia(言語)と奮闘中。

[めざせカグルマスター](https://kaggle.regonn.tokyo/)

## 2017年に触ってきたもの

### ゼロから作るDeepLearning
<amp-youtube
  data-videoid="oA6QfWUJj-8"
  layout="responsive"
  width="480"
  height="270">
</amp-youtube>
書籍の[ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装](http://amzn.to/2zuegLn)を参考にDeepLearningのモデルを構築していく。

最初はパーセプトロンの実装から、最終的にはMNISTの画像判別の部分までやっている。
ここで、ディープラーニングに関する基礎的な内容をPythonを使ってゼロから作ってみて、どのような計算や方法が使われているのか知ることができた。

#### 何ができるようになったか
画像を分類することが可能になった。
現状は、1枚毎に用意されている手書きの数字から書かれている数字を分類できる。

### Keras で時系列データ予測
<amp-youtube
  data-videoid="tHiZOZoRW4s"
  layout="responsive"
  width="480"
  height="270">
</amp-youtube>
今度はKerasというディープラーニング用のライブラリを使って時系列データ(回帰分析)を扱った。
RNN(Recurrent Neural Network) から LSTM(Long Short-Term Memory) を利用して、過去の情報を保持しながらの数値予測をしている。
KerasはTensorFlowやTheanoをラッパーしておりモデルを構築しやすかったし、大抵の機能(LSTM)などが揃っているため、特定のニューラルネットワークの層がどういった役割かについて概要を知っていれば扱えて便利だった。

#### 何ができるようになったか
株価予測など過去の情報から未来の傾向を予測することができるようになった。(もちろん精度はまだ良くない)

### Random Forestで分類問題
<amp-youtube
  data-videoid="fvak-0P79pU"
  layout="responsive"
  width="480"
  height="270">
</amp-youtube>
決定木を組み合わせたランダムフォレストをPythonで実装してみて、分類問題を解いていく。
他の機械学習のアルゴリズムと比べてもロジックが複雑ではなく出来上がった結果も見やすいため、ライブラリを使わず自作しても、それなりに精度を出すことができた。機械学習系を触るのであれば、ここらへんから触り出してみると、最初から結果を出せるので良いかもしれない。

#### 何ができるようになったか
画像だけでなく、複数の数値などから対象のものを分類することができるようになった。
(今回は花の花弁の長さ情報から種類を特定できるように)

### Kaggleマスターを目指していく
<amp-youtube
  data-videoid="rYGwq5JDr7M"
  layout="responsive"
  width="480"
  height="270">
</amp-youtube>
メジャーな機械学習のライブラリや技術は触ることができてきたので、Kaggleというデータサイエンスコンペティションサイトでデータサイエンスの腕を磨いていくことに。
この辺りで自分はJuliaという言語を知り、気に入ったのでJuliaを使って色々挑戦している。

#### 何ができるようになったか
簡単な統計処理(Nullな値をどう扱うか等)やどういったツールを使うと効率的に求めることができるかも分かってきた。あと、AWSでGPUを使って計算処理する方法など。

### 来年に向けてやっていきたいこと、将来像
Kaggleをやりだして感じたことは、統計に関する知識が自分に足りていないことだ。
実際にKaggleのアンケートでDeepLearning(NN)を使っている人は意外と少なかったりして、統計処理をしっかりと組み合わせて、分析や予測をしている人たちがやっぱり強い。

今年一年で道具は使えるようになってきたので、来年はもう少し統計や数学に関する知識を身につけていきたい。自分にとってデータサイエンスの分野は熱中できるため今後もやっていくと思う。

最近興味が出てきた技術は量子コンピュータ分野だ。
[量子コンピュータが人工知能を加速する](http://amzn.to/2zxinGB)という本を読んで、最近の量子コンピュータ系の技術が機械学習に応用できそうという話を知った。幸い大学時代は応用物理学を学んでいたので、量子力学に関する知識は多少持ち合わせているのと、マイクロソフトが今年中には量子コンピュータのプログラミング言語を発表するらしい。
[マイクロソフト、量子コンピュータ向けプログラミング言語を発表 \- ZDNet Japan](https://japan.zdnet.com/article/35107801/)
なので、来年は統計・数学・量子力学などの大学時代を思い出す内容を再び学んでいくことになりそうな気がする。
